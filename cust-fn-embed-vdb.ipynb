{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023fa8d5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-02T07:30:14.672648Z",
     "iopub.status.busy": "2024-05-02T07:30:14.671819Z",
     "iopub.status.idle": "2024-05-02T07:30:15.723811Z",
     "shell.execute_reply": "2024-05-02T07:30:15.722626Z"
    },
    "papermill": {
     "duration": 1.061026,
     "end_time": "2024-05-02T07:30:15.726570",
     "exception": false,
     "start_time": "2024-05-02T07:30:14.665544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af9fd06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:30:15.737085Z",
     "iopub.status.busy": "2024-05-02T07:30:15.736536Z",
     "iopub.status.idle": "2024-05-02T07:32:22.631829Z",
     "shell.execute_reply": "2024-05-02T07:32:22.630297Z"
    },
    "papermill": {
     "duration": 126.903628,
     "end_time": "2024-05-02T07:32:22.634570",
     "exception": false,
     "start_time": "2024-05-02T07:30:15.730942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.327\r\n",
      "  Downloading langchain-0.0.327-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (3.9.1)\r\n",
      "Collecting anyio<4.0 (from langchain==0.0.327)\r\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (4.0.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (0.6.4)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (1.33)\r\n",
      "Collecting langsmith<0.1.0,>=0.0.52 (from langchain==0.0.327)\r\n",
      "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.327) (8.2.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.327) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.327) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.327) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.327) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.327) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.327) (3.6)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.327) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.327) (1.2.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.327) (3.21.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.327) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.327) (2.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.327) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.327) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.327) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.327) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.327) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.327) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.327) (3.0.3)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.327) (21.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.327) (1.0.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.327) (3.1.1)\r\n",
      "Downloading langchain-0.0.327-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langsmith-0.0.92-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: anyio, langsmith, langchain\r\n",
      "  Attempting uninstall: anyio\r\n",
      "    Found existing installation: anyio 4.2.0\r\n",
      "    Uninstalling anyio-4.2.0:\r\n",
      "      Successfully uninstalled anyio-4.2.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed anyio-3.7.1 langchain-0.0.327 langsmith-0.0.92\r\n",
      "Collecting langchain-community==0.0.25\r\n",
      "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.0.25) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.0.25) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.0.25) (3.9.1)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.0.25) (0.6.4)\r\n",
      "Collecting langchain-core<0.2.0,>=0.1.28 (from langchain-community==0.0.25)\r\n",
      "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-community==0.0.25)\r\n",
      "  Downloading langsmith-0.1.52-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.0.25) (1.26.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.0.25) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.0.25) (8.2.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.25) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.25) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.25) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.25) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.25) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.25) (4.0.3)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.25) (3.21.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.25) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-community==0.0.25) (1.33)\r\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.28->langchain-community==0.0.25)\r\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-community==0.0.25) (2.5.3)\r\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.25)\r\n",
      "  Downloading orjson-3.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.0.25) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.0.25) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.0.25) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.0.25) (2024.2.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.25) (4.9.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.25) (3.0.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.28->langchain-community==0.0.25) (2.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-community==0.0.25) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-community==0.0.25) (2.14.6)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.25) (1.0.0)\r\n",
      "Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_core-0.1.48-py3-none-any.whl (302 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langsmith-0.1.52-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading orjson-3.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-community\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: orjson\r\n",
      "    Found existing installation: orjson 3.9.10\r\n",
      "    Uninstalling orjson-3.9.10:\r\n",
      "      Successfully uninstalled orjson-3.9.10\r\n",
      "  Attempting uninstall: langsmith\r\n",
      "    Found existing installation: langsmith 0.0.92\r\n",
      "    Uninstalling langsmith-0.0.92:\r\n",
      "      Successfully uninstalled langsmith-0.0.92\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.9.3 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\r\n",
      "jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "langchain 0.0.327 requires langsmith<0.1.0,>=0.0.52, but you have langsmith 0.1.52 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed langchain-community-0.0.25 langchain-core-0.1.48 langsmith-0.1.52 orjson-3.10.2 packaging-23.2\r\n",
      "Collecting langchain-core==0.1.28\r\n",
      "  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.1.28) (6.0.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.1.28) (3.7.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.1.28) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.1.28) (0.1.52)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.1.28) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.1.28) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.1.28) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.1.28) (8.2.3)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core==0.1.28) (3.6)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core==0.1.28) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core==0.1.28) (1.2.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.1.28) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core==0.1.28) (3.10.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core==0.1.28) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core==0.1.28) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core==0.1.28) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-core==0.1.28) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-core==0.1.28) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-core==0.1.28) (2024.2.2)\r\n",
      "Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: langchain-core\r\n",
      "  Attempting uninstall: langchain-core\r\n",
      "    Found existing installation: langchain-core 0.1.48\r\n",
      "    Uninstalling langchain-core-0.1.48:\r\n",
      "      Successfully uninstalled langchain-core-0.1.48\r\n",
      "Successfully installed langchain-core-0.1.28\r\n",
      "Collecting langchain-openai==0.0.8\r\n",
      "  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in /opt/conda/lib/python3.10/site-packages (from langchain-openai==0.0.8) (0.1.28)\r\n",
      "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai==0.0.8)\r\n",
      "  Downloading openai-1.25.0-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain-openai==0.0.8)\r\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (6.0.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (3.7.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (0.1.52)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (8.2.3)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.27.0)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.9.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2023.12.25)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (3.10.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.14.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (1.26.18)\r\n",
      "Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\r\n",
      "Downloading openai-1.25.0-py3-none-any.whl (312 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-openai\r\n",
      "Successfully installed langchain-openai-0.0.8 openai-1.25.0 tiktoken-0.6.0\r\n",
      "Collecting faiss-cpu==1.7.4\r\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\r\n",
      "Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\r\n",
      "Successfully installed faiss-cpu-1.7.4\r\n",
      "Collecting openai==0.28.1\r\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai==0.28.1) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai==0.28.1) (4.66.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai==0.28.1) (3.9.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (4.0.3)\r\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: openai\r\n",
      "  Attempting uninstall: openai\r\n",
      "    Found existing installation: openai 1.25.0\r\n",
      "    Uninstalling openai-1.25.0:\r\n",
      "      Successfully uninstalled openai-1.25.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "langchain-openai 0.0.8 requires openai<2.0.0,>=1.10.0, but you have openai 0.28.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed openai-0.28.1\r\n",
      "Collecting transformers==4.38.1\r\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (0.22.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1) (2024.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (2024.2.2)\r\n",
      "Downloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.39.3\r\n",
      "    Uninstalling transformers-4.39.3:\r\n",
      "      Successfully uninstalled transformers-4.39.3\r\n",
      "Successfully installed transformers-4.38.1\r\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /opt/conda/lib/python3.10/site-packages (0.6.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0) (2023.12.25)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (2024.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.0.327\n",
    "!pip install langchain-community==0.0.25\n",
    "!pip install langchain-core==0.1.28\n",
    "!pip install langchain-openai==0.0.8\n",
    "!pip install faiss-cpu==1.7.4\n",
    "!pip install openai==0.28.1\n",
    "!pip install transformers==4.38.1\n",
    "!pip install tiktoken==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a5c470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:22.658669Z",
     "iopub.status.busy": "2024-05-02T07:32:22.658247Z",
     "iopub.status.idle": "2024-05-02T07:32:22.663357Z",
     "shell.execute_reply": "2024-05-02T07:32:22.662331Z"
    },
    "papermill": {
     "duration": 0.019722,
     "end_time": "2024-05-02T07:32:22.665454",
     "exception": false,
     "start_time": "2024-05-02T07:32:22.645732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GenAICentral-cust-fn-embed-vdb-12-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e540df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:22.688044Z",
     "iopub.status.busy": "2024-05-02T07:32:22.687647Z",
     "iopub.status.idle": "2024-05-02T07:32:23.333213Z",
     "shell.execute_reply": "2024-05-02T07:32:23.331897Z"
    },
    "papermill": {
     "duration": 0.660026,
     "end_time": "2024-05-02T07:32:23.335963",
     "exception": false,
     "start_time": "2024-05-02T07:32:22.675937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6f744f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.360029Z",
     "iopub.status.busy": "2024-05-02T07:32:23.358960Z",
     "iopub.status.idle": "2024-05-02T07:32:23.365119Z",
     "shell.execute_reply": "2024-05-02T07:32:23.363916Z"
    },
    "papermill": {
     "duration": 0.020396,
     "end_time": "2024-05-02T07:32:23.367150",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.346754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Configuration- for azure\n",
    "root_path = '/content/drive/MyDrive/Data/'\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://asdf.openai.azure.com/\"\n",
    "openai.api_key =  \"\"\n",
    "openai.api_version = \"2023-10-15-preview\"\n",
    "model_name = \"text-embedding-ada-002\"\n",
    "engine_name = \"TEA\"\n",
    "chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f951953b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.391674Z",
     "iopub.status.busy": "2024-05-02T07:32:23.391257Z",
     "iopub.status.idle": "2024-05-02T07:32:23.399800Z",
     "shell.execute_reply": "2024-05-02T07:32:23.398731Z"
    },
    "papermill": {
     "duration": 0.023079,
     "end_time": "2024-05-02T07:32:23.402020",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.378941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_xcel_data(file_path):\n",
    "\n",
    "    documents = []\n",
    "    num_documents = []\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        data = df.astype(str)\n",
    "        cols = ['id', 'name', 'description','rootCause', 'solution']\n",
    "\n",
    "        data = data[cols]\n",
    "        json_lines = [json.dumps(row.to_dict()) for index , row in data.iterrows()]\n",
    "        documents = [Document(page_content = json_line) for json_line in json_lines]\n",
    "        print(f\"The json conversion is done.\")\n",
    "\n",
    "        num_data = data['issueNum']\n",
    "        num_json_lines = [json.dumps({'issueNum':row}) for index , row in num_data.items()]\n",
    "        num_documents = [Document(page_content = json_line) for json_line in num_json_lines]\n",
    "        print(f\"The json conversion is done for Issue Number Docs.\")\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Error in parsing the excel file\")\n",
    "        raise Exception\n",
    "\n",
    "    return documents, num_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1db135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.425083Z",
     "iopub.status.busy": "2024-05-02T07:32:23.424477Z",
     "iopub.status.idle": "2024-05-02T07:32:23.433197Z",
     "shell.execute_reply": "2024-05-02T07:32:23.432402Z"
    },
    "papermill": {
     "duration": 0.022772,
     "end_time": "2024-05-02T07:32:23.435400",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.412628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def create_vectordb(documents,embeddings,path):\n",
    "    try:\n",
    "        if len(documents) <= 500:\n",
    "            print(f\"Small file, using direct call {len(documents)}\")\n",
    "            db = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "        else:\n",
    "            print(f\"Large file recieved {len(documents)}.\")\n",
    "            batch_size = 500\n",
    "            print(f\"Batch size is {batch_size}\")\n",
    "            db = FAISS.from_documents(documents[:batch_size], embeddings)\n",
    "            index = batch_size\n",
    "\n",
    "            while index < len(documents) :\n",
    "                db_temp = FAISS.from_documents(documents[index:index+batch_size], embeddings)\n",
    "                db.merge_from(db_temp)\n",
    "                index+=batch_size\n",
    "                print(f\"Progess of DB {index}\")\n",
    "\n",
    "    except openai.error.RateLimitError :\n",
    "            print(f\"getting timeout error so running long process for{len(documents)} documents.\")\n",
    "            print(documents[0])\n",
    "            db = FAISS.from_documents(documents[0:1], embeddings)\n",
    "            index = 1\n",
    "            while index < len(documents) :\n",
    "                db_temp = FAISS.from_documents(documents[index:index+1], embeddings)\n",
    "                db.merge_from(db_temp)\n",
    "                index+=1\n",
    "                time.sleep(0.12)\n",
    "    db.save_local(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5a893c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.458031Z",
     "iopub.status.busy": "2024-05-02T07:32:23.457357Z",
     "iopub.status.idle": "2024-05-02T07:32:23.462930Z",
     "shell.execute_reply": "2024-05-02T07:32:23.462189Z"
    },
    "papermill": {
     "duration": 0.019283,
     "end_time": "2024-05-02T07:32:23.464949",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.445666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_azure_openAI_embeddings():\n",
    "\n",
    "    embeddings = \"\"\n",
    "    try:\n",
    "        embeddings =OpenAIEmbeddings(\n",
    "                                openai_api_key = openai.api_key,\n",
    "                                model = model_name,\n",
    "                                engine=engine_name,\n",
    "                                deployment=engine_name,\n",
    "                                chunk_size=chunk_size)\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Error in getting openAI embeddings\")\n",
    "        raise Exception\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "375b624b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.487758Z",
     "iopub.status.busy": "2024-05-02T07:32:23.487090Z",
     "iopub.status.idle": "2024-05-02T07:32:23.492491Z",
     "shell.execute_reply": "2024-05-02T07:32:23.491549Z"
    },
    "papermill": {
     "duration": 0.019389,
     "end_time": "2024-05-02T07:32:23.494561",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.475172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_faiss_index(path):\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    idx = list(data[1].values())\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986a6f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.518962Z",
     "iopub.status.busy": "2024-05-02T07:32:23.518344Z",
     "iopub.status.idle": "2024-05-02T07:32:23.529314Z",
     "shell.execute_reply": "2024-05-02T07:32:23.528346Z"
    },
    "papermill": {
     "duration": 0.026792,
     "end_time": "2024-05-02T07:32:23.531586",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.504794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embedd(file_path,vdb_name):\n",
    "\n",
    "    db = None\n",
    "    num_db = None\n",
    "    num_vdb_name = 'num_' + vdb_name\n",
    "    try:\n",
    "        print(\"file_path %s\",file_path)\n",
    "        print(\"Vectordb name %s\",vdb_name)\n",
    "        print(\"Issue Num Vectordb name %s\",vdb_name + 'num')\n",
    "        print(\"Model Name %s\", model_name)\n",
    "        print(\"chunk size %s\", chunk_size)\n",
    "        file_extension = file_path.split(\".\")[-1]\n",
    "        print(\"file extension %s\",file_extension)\n",
    "\n",
    "        print(\"\\n\\nStarting Embedding for files\")\n",
    "        #get embeddings\n",
    "        embeddings = get_azure_openAI_embeddings()\n",
    "\n",
    "        #for excel files\n",
    "        if file_extension == \"xlsx\" :\n",
    "            print(\"xlsx file given as input to parser\")\n",
    "            documents, num_documents = read_xcel_data(file_path)\n",
    "\n",
    "        elif file_extension == \"csv\" :\n",
    "            print(\"csv file given as input to parser\")\n",
    "            documents, num_documents = read_csv_data(file_path)\n",
    "\n",
    "        else:\n",
    "            print(\"File type is not supported.\")\n",
    "            print(\"file extention is not xlsx please check the file type and proceed\")\n",
    "\n",
    "        #TODO pass json data to below line\n",
    "        print(\"Creating Vector db for complete docs and vector_db path is \",root_path + vdb_name)\n",
    "        # documents, num_documents = read_xcel_data(file_path)\n",
    "        create_vectordb(documents,embeddings,root_path + vdb_name)\n",
    "        time.sleep(60)\n",
    "        print(\"Creating Vector db for Issue Number docs and vector_db path is \",root_path + num_vdb_name)\n",
    "        create_vectordb(num_documents,embeddings,root_path + num_vdb_name)\n",
    "\n",
    "        # Document Swapping\n",
    "        try:\n",
    "            db_idx = get_faiss_index(root_path + vdb_name + '/index.pkl')\n",
    "            num_db_idx = get_faiss_index(root_path + num_vdb_name + '/index.pkl')\n",
    "\n",
    "            db = FAISS.load_local(root_path + vdb_name,embeddings)\n",
    "            num_db = FAISS.load_local(root_path + num_vdb_name,embeddings)\n",
    "\n",
    "            for i in range(len(db_idx)):\n",
    "                replace_docs = db.docstore._dict[db_idx[i]]\n",
    "                num_db.docstore._dict[num_db_idx[i]] = replace_docs\n",
    "\n",
    "            num_db.save_local(root_path + num_vdb_name)\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error while swapping documents\")\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Error in generating embeddings\")\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247bfe7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.554305Z",
     "iopub.status.busy": "2024-05-02T07:32:23.553933Z",
     "iopub.status.idle": "2024-05-02T07:32:23.558786Z",
     "shell.execute_reply": "2024-05-02T07:32:23.557657Z"
    },
    "papermill": {
     "duration": 0.018677,
     "end_time": "2024-05-02T07:32:23.560789",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.542112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embedd('/content/drive/MyDrive/Data/data_len/qqdts-data.csv','qqdts_vdb')\n",
    "\n",
    "# output--\n",
    "# file_path %s /content/drive/MyDrive/Data/data_len/qqdts-data.csv\n",
    "# Vectordb name %s qqdts_vdb\n",
    "# Issue Num Vectordb name %s qqdts_vdbnum\n",
    "# Model Name %s text-embedding-ada-002\n",
    "# chunk size %s 512\n",
    "# file extension %s csv\n",
    "\n",
    "\n",
    "# Starting Embedding for files\n",
    "# csv file given as input to parser\n",
    "# /usr/local/lib/python3.10/dist-packages/langchain/embeddings/openai.py:217: UserWarning: WARNING! engine is not default parameter.\n",
    "#                     engine was transferred to model_kwargs.\n",
    "#                     Please confirm that engine is what you intended.\n",
    "#   warnings.warn(\n",
    "# The json conversion is done.\n",
    "# The json conversion is done for Issue Number Docs.\n",
    "# Creating Vector db for complete docs and vector_db path is  /content/drive/MyDrive/Data/qqdts_vdb\n",
    "# Small file, using direct call 491\n",
    "# Creating Vector db for Issue Number docs and vector_db path is  /content/drive/MyDrive/Data/num_qqdts_vdb\n",
    "# Small file, using direct call 491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05266199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.583768Z",
     "iopub.status.busy": "2024-05-02T07:32:23.582655Z",
     "iopub.status.idle": "2024-05-02T07:32:23.588785Z",
     "shell.execute_reply": "2024-05-02T07:32:23.587779Z"
    },
    "papermill": {
     "duration": 0.019963,
     "end_time": "2024-05-02T07:32:23.590999",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.571036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def azure_llm(temperature, max_tokens, prompt):\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "              engine = engine,\n",
    "              # Here prompt is message text\n",
    "              messages = prompt,\n",
    "              temperature = temperature,\n",
    "              max_tokens = max_tokens,\n",
    "              top_p=0.2,\n",
    "              frequency_penalty = 0,\n",
    "              presence_penalty = 0)\n",
    "\n",
    "\n",
    "    # text = response['choices'][0]['message']['content'].strip()\n",
    "    text = response.choices[0].message.content\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ef014da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:23.613868Z",
     "iopub.status.busy": "2024-05-02T07:32:23.613487Z",
     "iopub.status.idle": "2024-05-02T07:32:23.620842Z",
     "shell.execute_reply": "2024-05-02T07:32:23.619705Z"
    },
    "papermill": {
     "duration": 0.021331,
     "end_time": "2024-05-02T07:32:23.622980",
     "exception": false,
     "start_time": "2024-05-02T07:32:23.601649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# db = FAISS.load_local('/content/drive/MyDrive/Data/QQDTS-cases-data-240424/new_qdts_data_fixed0205',embeddings)\n",
    "\n",
    "prompts = \"\"\"\n",
    "Answer the question from the given context.\n",
    "Keep answer to be precise and informative.\n",
    "Context is a customer ticket data created for the products having issue.\n",
    "\n",
    "question: {question}\n",
    "\n",
    "context : {context}\n",
    "\"\"\"\n",
    "\n",
    "def llm_answer(query):\n",
    "    temperature = 0.1\n",
    "    max_tokens = 200\n",
    "\n",
    "    retriever = db.as_retriever(search_kwargs = {\"k\": 5})\n",
    "    documents = retriever.get_relevant_documents(query)\n",
    "\n",
    "    context = \"\"\n",
    "    for page in documents:\n",
    "        context+=page.page_content\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompts).format_messages(\n",
    "    question = query,\n",
    "    context = context\n",
    "    )\n",
    "    message_text=[{\"role\": \"system\", \"content\": prompt[0].content}]\n",
    "\n",
    "    resp = azure_llm(temperature, max_tokens, message_text)\n",
    "    return resp, message_text"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 132.595629,
   "end_time": "2024-05-02T07:32:24.254495",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-02T07:30:11.658866",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
