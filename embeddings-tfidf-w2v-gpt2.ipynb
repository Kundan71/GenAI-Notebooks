{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4693fe49",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-07T05:48:47.912372Z",
     "iopub.status.busy": "2024-04-07T05:48:47.911784Z",
     "iopub.status.idle": "2024-04-07T05:48:48.887348Z",
     "shell.execute_reply": "2024-04-07T05:48:48.885839Z"
    },
    "papermill": {
     "duration": 0.992429,
     "end_time": "2024-04-07T05:48:48.889986",
     "exception": false,
     "start_time": "2024-04-07T05:48:47.897557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/customer-support-ticket-dataset/customer_support_tickets.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d5fe1e",
   "metadata": {
    "papermill": {
     "duration": 0.011307,
     "end_time": "2024-04-07T05:48:48.913251",
     "exception": false,
     "start_time": "2024-04-07T05:48:48.901944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Library Install**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e03b8bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:48:48.939199Z",
     "iopub.status.busy": "2024-04-07T05:48:48.938671Z",
     "iopub.status.idle": "2024-04-07T05:49:16.291603Z",
     "shell.execute_reply": "2024-04-07T05:49:16.290022Z"
    },
    "papermill": {
     "duration": 27.370004,
     "end_time": "2024-04-07T05:49:16.294944",
     "exception": false,
     "start_time": "2024-04-07T05:48:48.924940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\r\n",
      "  Downloading openai-1.16.2-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Collecting sentence-transformers\r\n",
      "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting unstructured\r\n",
      "  Downloading unstructured-0.13.2-py3-none-any.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.38.1)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2+cpu)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.20.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\r\n",
      "Collecting chardet (from unstructured)\r\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Collecting filetype (from unstructured)\r\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting python-magic (from unstructured)\r\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from unstructured) (5.1.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from unstructured) (3.2.4)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from unstructured) (0.9.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from unstructured) (2.31.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from unstructured) (4.12.2)\r\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from unstructured) (2.10.1)\r\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from unstructured) (0.6.4)\r\n",
      "Collecting python-iso639 (from unstructured)\r\n",
      "  Downloading python_iso639-2024.2.7-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting langdetect (from unstructured)\r\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: rapidfuzz in /opt/conda/lib/python3.10/site-packages (from unstructured) (3.6.1)\r\n",
      "Requirement already satisfied: backoff in /opt/conda/lib/python3.10/site-packages (from unstructured) (2.2.1)\r\n",
      "Collecting unstructured-client<=0.18.0 (from unstructured)\r\n",
      "  Downloading unstructured_client-0.18.0-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from unstructured) (1.14.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\r\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from unstructured-client<=0.18.0->unstructured) (3.3.2)\r\n",
      "Collecting dataclasses-json-speakeasy>=0.5.11 (from unstructured-client<=0.18.0->unstructured)\r\n",
      "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client<=0.18.0->unstructured)\r\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: marshmallow>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from unstructured-client<=0.18.0->unstructured) (3.20.2)\r\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from unstructured-client<=0.18.0->unstructured) (1.0.0)\r\n",
      "Collecting packaging>=20.9 (from huggingface-hub>=0.15.1->sentence-transformers)\r\n",
      "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from unstructured-client<=0.18.0->unstructured) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from unstructured-client<=0.18.0->unstructured) (1.16.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from unstructured-client<=0.18.0->unstructured) (0.9.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.18 in /opt/conda/lib/python3.10/site-packages (from unstructured-client<=0.18.0->unstructured) (1.26.18)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.5)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Downloading openai-1.16.2-py3-none-any.whl (267 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading unstructured-0.13.2-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\r\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\r\n",
      "Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\r\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading packaging-24.0-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: langdetect\r\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=bbd4b78cab1b40390939129db4d1d430170054dc74771f8426eb59afcd1e327f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\r\n",
      "Successfully built langdetect\r\n",
      "Installing collected packages: filetype, python-magic, python-iso639, packaging, langdetect, jsonpath-python, faiss-cpu, chardet, openai, dataclasses-json-speakeasy, unstructured-client, unstructured, sentence-transformers\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.8.1 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.0 which is incompatible.\r\n",
      "jupyterlab 4.1.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed chardet-5.2.0 dataclasses-json-speakeasy-0.5.11 faiss-cpu-1.8.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 openai-1.16.2 packaging-24.0 python-iso639-2024.2.7 python-magic-0.4.27 sentence-transformers-2.6.1 unstructured-0.13.2 unstructured-client-0.18.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai faiss-cpu sentence-transformers unstructured "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87e4ad",
   "metadata": {
    "papermill": {
     "duration": 0.018041,
     "end_time": "2024-04-07T05:49:16.331994",
     "exception": false,
     "start_time": "2024-04-07T05:49:16.313953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Data Loading and Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c0e3d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:16.373694Z",
     "iopub.status.busy": "2024-04-07T05:49:16.372076Z",
     "iopub.status.idle": "2024-04-07T05:49:16.570959Z",
     "shell.execute_reply": "2024-04-07T05:49:16.569912Z"
    },
    "papermill": {
     "duration": 0.222961,
     "end_time": "2024-04-07T05:49:16.573927",
     "exception": false,
     "start_time": "2024-04-07T05:49:16.350966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age',\n",
      "       'Customer Gender', 'Product Purchased', 'Date of Purchase',\n",
      "       'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status',\n",
      "       'Resolution', 'Ticket Priority', 'Ticket Channel',\n",
      "       'First Response Time', 'Time to Resolution',\n",
      "       'Customer Satisfaction Rating'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Customer Email</th>\n",
       "      <th>Customer Age</th>\n",
       "      <th>Customer Gender</th>\n",
       "      <th>Product Purchased</th>\n",
       "      <th>Date of Purchase</th>\n",
       "      <th>Ticket Type</th>\n",
       "      <th>Ticket Subject</th>\n",
       "      <th>Ticket Description</th>\n",
       "      <th>Ticket Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Ticket Priority</th>\n",
       "      <th>Ticket Channel</th>\n",
       "      <th>First Response Time</th>\n",
       "      <th>Time to Resolution</th>\n",
       "      <th>Customer Satisfaction Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marisa Obrien</td>\n",
       "      <td>carrollallison@example.com</td>\n",
       "      <td>32</td>\n",
       "      <td>Other</td>\n",
       "      <td>GoPro Hero</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Product setup</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Pending Customer Response</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Social media</td>\n",
       "      <td>2023-06-01 12:15:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jessica Rios</td>\n",
       "      <td>clarkeashley@example.com</td>\n",
       "      <td>42</td>\n",
       "      <td>Female</td>\n",
       "      <td>LG Smart TV</td>\n",
       "      <td>2021-05-22</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Peripheral compatibility</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Pending Customer Response</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Chat</td>\n",
       "      <td>2023-06-01 16:45:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Christopher Robbins</td>\n",
       "      <td>gonzalestracy@example.com</td>\n",
       "      <td>48</td>\n",
       "      <td>Other</td>\n",
       "      <td>Dell XPS</td>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Network problem</td>\n",
       "      <td>I'm facing a problem with my {product_purchase...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Case maybe show recently my computer follow.</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social media</td>\n",
       "      <td>2023-06-01 11:14:38</td>\n",
       "      <td>2023-06-01 18:05:38</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
       "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
       "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
       "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
       "\n",
       "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
       "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
       "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
       "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
       "\n",
       "             Ticket Subject  \\\n",
       "0             Product setup   \n",
       "1  Peripheral compatibility   \n",
       "2           Network problem   \n",
       "\n",
       "                                  Ticket Description  \\\n",
       "0  I'm having an issue with the {product_purchase...   \n",
       "1  I'm having an issue with the {product_purchase...   \n",
       "2  I'm facing a problem with my {product_purchase...   \n",
       "\n",
       "               Ticket Status                                    Resolution  \\\n",
       "0  Pending Customer Response                                           NaN   \n",
       "1  Pending Customer Response                                           NaN   \n",
       "2                     Closed  Case maybe show recently my computer follow.   \n",
       "\n",
       "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
       "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
       "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
       "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
       "\n",
       "   Customer Satisfaction Rating  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           3.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/customer-support-ticket-dataset/customer_support_tickets.csv')\n",
    "print(df.columns)\n",
    "# df0 = df[['issueNum','releaseName','solution']]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1310b676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:16.615181Z",
     "iopub.status.busy": "2024-04-07T05:49:16.614169Z",
     "iopub.status.idle": "2024-04-07T05:49:16.621007Z",
     "shell.execute_reply": "2024-04-07T05:49:16.619764Z"
    },
    "papermill": {
     "duration": 0.029771,
     "end_time": "2024-04-07T05:49:16.624100",
     "exception": false,
     "start_time": "2024-04-07T05:49:16.594329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concatenate_text(x):\n",
    "    # pattern = r'\\[(\\d+)-(\\d+)\\)'\n",
    "    full_text = [\n",
    "        f\"Ticket Subject {x['Ticket Subject']}\",\n",
    "        f\"\\nCustomer Name {x['Customer Name']}\",\n",
    "        f\"\\nDescription {x['Ticket Description']}\",\n",
    "        f\"\\nSolution is {x['Resolution']}\"\n",
    "    ]\n",
    "    return ' '.join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4cc82f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:16.662355Z",
     "iopub.status.busy": "2024-04-07T05:49:16.661951Z",
     "iopub.status.idle": "2024-04-07T05:49:16.934561Z",
     "shell.execute_reply": "2024-04-07T05:49:16.933290Z"
    },
    "papermill": {
     "duration": 0.295588,
     "end_time": "2024-04-07T05:49:16.937848",
     "exception": false,
     "start_time": "2024-04-07T05:49:16.642260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0 = df.copy()\n",
    "df0['Complete description'] = df0.apply(lambda x: concatenate_text(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d89ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:16.977137Z",
     "iopub.status.busy": "2024-04-07T05:49:16.976706Z",
     "iopub.status.idle": "2024-04-07T05:49:16.985697Z",
     "shell.execute_reply": "2024-04-07T05:49:16.984146Z"
    },
    "papermill": {
     "duration": 0.032473,
     "end_time": "2024-04-07T05:49:16.988567",
     "exception": false,
     "start_time": "2024-04-07T05:49:16.956094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ticket Subject Product setup \\nCustomer Name Marisa Obrien \\nDescription I'm having an issue with the {product_purchased}. Please assist.\\n\\nYour billing zip code is: 71701.\\n\\nWe appreciate that you have requested a website address.\\n\\nPlease double check your email address. I've tried troubleshooting steps mentioned in the user manual, but the issue persists. \\nSolution is nan\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['Complete description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f92ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:17.032504Z",
     "iopub.status.busy": "2024-04-07T05:49:17.031299Z",
     "iopub.status.idle": "2024-04-07T05:49:17.076785Z",
     "shell.execute_reply": "2024-04-07T05:49:17.075437Z"
    },
    "papermill": {
     "duration": 0.070108,
     "end_time": "2024-04-07T05:49:17.079240",
     "exception": false,
     "start_time": "2024-04-07T05:49:17.009132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8469 entries, 0 to 8468\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Ticket ID                     8469 non-null   int64  \n",
      " 1   Customer Name                 8469 non-null   object \n",
      " 2   Customer Email                8469 non-null   object \n",
      " 3   Customer Age                  8469 non-null   int64  \n",
      " 4   Customer Gender               8469 non-null   object \n",
      " 5   Product Purchased             8469 non-null   object \n",
      " 6   Date of Purchase              8469 non-null   object \n",
      " 7   Ticket Type                   8469 non-null   object \n",
      " 8   Ticket Subject                8469 non-null   object \n",
      " 9   Ticket Description            8469 non-null   object \n",
      " 10  Ticket Status                 8469 non-null   object \n",
      " 11  Resolution                    2769 non-null   object \n",
      " 12  Ticket Priority               8469 non-null   object \n",
      " 13  Ticket Channel                8469 non-null   object \n",
      " 14  First Response Time           5650 non-null   object \n",
      " 15  Time to Resolution            2769 non-null   object \n",
      " 16  Customer Satisfaction Rating  2769 non-null   float64\n",
      " 17  Complete description          8469 non-null   object \n",
      "dtypes: float64(1), int64(2), object(15)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0200549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:17.120569Z",
     "iopub.status.busy": "2024-04-07T05:49:17.119762Z",
     "iopub.status.idle": "2024-04-07T05:49:17.124132Z",
     "shell.execute_reply": "2024-04-07T05:49:17.123206Z"
    },
    "papermill": {
     "duration": 0.028135,
     "end_time": "2024-04-07T05:49:17.126737",
     "exception": false,
     "start_time": "2024-04-07T05:49:17.098602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# null_mask = df.isnull().any(axis=1)\n",
    "# null_rows = df[null_mask]\n",
    "\n",
    "# print(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1b06b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:17.165540Z",
     "iopub.status.busy": "2024-04-07T05:49:17.164875Z",
     "iopub.status.idle": "2024-04-07T05:49:17.169675Z",
     "shell.execute_reply": "2024-04-07T05:49:17.168402Z"
    },
    "papermill": {
     "duration": 0.027391,
     "end_time": "2024-04-07T05:49:17.172295",
     "exception": false,
     "start_time": "2024-04-07T05:49:17.144904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not_null_mask = df.notnull().all(axis=1)\n",
    "# not_null_rows = df[not_null_mask]\n",
    "\n",
    "# print(not_null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a76c9e31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:17.215189Z",
     "iopub.status.busy": "2024-04-07T05:49:17.214537Z",
     "iopub.status.idle": "2024-04-07T05:49:17.232220Z",
     "shell.execute_reply": "2024-04-07T05:49:17.230345Z"
    },
    "papermill": {
     "duration": 0.043082,
     "end_time": "2024-04-07T05:49:17.235862",
     "exception": false,
     "start_time": "2024-04-07T05:49:17.192780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2769, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = df0.loc[df['Resolution'].notnull()]\n",
    "df0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9b165",
   "metadata": {
    "papermill": {
     "duration": 0.018974,
     "end_time": "2024-04-07T05:49:17.274358",
     "exception": false,
     "start_time": "2024-04-07T05:49:17.255384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Tf-IDF Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbca2efb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:17.315934Z",
     "iopub.status.busy": "2024-04-07T05:49:17.315478Z",
     "iopub.status.idle": "2024-04-07T05:49:19.300419Z",
     "shell.execute_reply": "2024-04-07T05:49:19.298219Z"
    },
    "papermill": {
     "duration": 2.011647,
     "end_time": "2024-04-07T05:49:19.304542",
     "exception": false,
     "start_time": "2024-04-07T05:49:17.292895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "docs = df0['Complete description'].tolist()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the vectorizer to the data and transform the documents into TF-IDF embeddings\n",
    "tfidf_embeddings = tfidf_vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f12d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:19.349613Z",
     "iopub.status.busy": "2024-04-07T05:49:19.349145Z",
     "iopub.status.idle": "2024-04-07T05:49:19.354816Z",
     "shell.execute_reply": "2024-04-07T05:49:19.353230Z"
    },
    "papermill": {
     "duration": 0.033034,
     "end_time": "2024-04-07T05:49:19.357859",
     "exception": false,
     "start_time": "2024-04-07T05:49:19.324825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max_features = 1000\n",
    "# n_component = 10\n",
    "# svd = TruncatedSVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b1f471a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:19.401400Z",
     "iopub.status.busy": "2024-04-07T05:49:19.400917Z",
     "iopub.status.idle": "2024-04-07T05:49:19.532285Z",
     "shell.execute_reply": "2024-04-07T05:49:19.530014Z"
    },
    "papermill": {
     "duration": 0.159013,
     "end_time": "2024-04-07T05:49:19.537248",
     "exception": false,
     "start_time": "2024-04-07T05:49:19.378235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names n ['00' '000' '00015735595957' ... 'สสท' '家沙' '超地理伝獣']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Names n\",tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ce69b",
   "metadata": {
    "papermill": {
     "duration": 0.019419,
     "end_time": "2024-04-07T05:49:19.577216",
     "exception": false,
     "start_time": "2024-04-07T05:49:19.557797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Sparse Matrix size and embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8491f1ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:19.620454Z",
     "iopub.status.busy": "2024-04-07T05:49:19.620011Z",
     "iopub.status.idle": "2024-04-07T05:49:19.809234Z",
     "shell.execute_reply": "2024-04-07T05:49:19.807746Z"
    },
    "papermill": {
     "duration": 0.21523,
     "end_time": "2024-04-07T05:49:19.812947",
     "exception": false,
     "start_time": "2024-04-07T05:49:19.597717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix n (2769, 5092) n [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparse Matrix n\",tfidf_embeddings.shape,\"n\",tfidf_embeddings.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e03121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:19.855542Z",
     "iopub.status.busy": "2024-04-07T05:49:19.855087Z",
     "iopub.status.idle": "2024-04-07T05:49:19.864103Z",
     "shell.execute_reply": "2024-04-07T05:49:19.862541Z"
    },
    "papermill": {
     "duration": 0.034312,
     "end_time": "2024-04-07T05:49:19.866995",
     "exception": false,
     "start_time": "2024-04-07T05:49:19.832683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similarity_search(query_text):\n",
    "\n",
    "    query_embeddings = tfidf_vectorizer.fit_transform([query_text])\n",
    "\n",
    "    # Pad the query embedding with zeros to match the dimensionality of document embeddings\n",
    "    padding_size = tfidf_embeddings.shape[1] - query_embeddings.shape[1]\n",
    "    padded_query_embedding = np.pad(query_embeddings.toarray(), ((0, 0), (0, padding_size)), mode='constant')\n",
    "\n",
    "    # Calculate cosine similarity between documents\n",
    "    cosine_similarities = cosine_similarity(padded_query_embedding, tfidf_embeddings)\n",
    "    top_similar_docs_indices = cosine_similarities.argsort()[0][-4:-1][::-1]\n",
    "\n",
    "    for index in top_similar_docs_indices:\n",
    "        print(docs[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c88c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:19.912155Z",
     "iopub.status.busy": "2024-04-07T05:49:19.911630Z",
     "iopub.status.idle": "2024-04-07T05:49:19.922796Z",
     "shell.execute_reply": "2024-04-07T05:49:19.920790Z"
    },
    "papermill": {
     "duration": 0.039794,
     "end_time": "2024-04-07T05:49:19.927332",
     "exception": false,
     "start_time": "2024-04-07T05:49:19.887538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age',\n",
       "       'Customer Gender', 'Product Purchased', 'Date of Purchase',\n",
       "       'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status',\n",
       "       'Resolution', 'Ticket Priority', 'Ticket Channel',\n",
       "       'First Response Time', 'Time to Resolution',\n",
       "       'Customer Satisfaction Rating', 'Complete description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f9b9651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:19.970043Z",
     "iopub.status.busy": "2024-04-07T05:49:19.969529Z",
     "iopub.status.idle": "2024-04-07T05:49:19.977612Z",
     "shell.execute_reply": "2024-04-07T05:49:19.976363Z"
    },
    "papermill": {
     "duration": 0.031606,
     "end_time": "2024-04-07T05:49:19.980194",
     "exception": false,
     "start_time": "2024-04-07T05:49:19.948588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autodesk AutoCAD'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['Product Purchased'].iloc[456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77527eb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:20.023974Z",
     "iopub.status.busy": "2024-04-07T05:49:20.023494Z",
     "iopub.status.idle": "2024-04-07T05:49:20.034136Z",
     "shell.execute_reply": "2024-04-07T05:49:20.032614Z"
    },
    "papermill": {
     "duration": 0.03634,
     "end_time": "2024-04-07T05:49:20.037238",
     "exception": false,
     "start_time": "2024-04-07T05:49:20.000898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm having an issue with the {product_purchased}. Please assist.\\n\\nQ: Can I buy more than one copy of the item?\\n\\nA: All sales are limited to 1 (1) copy. (Except for I need assistance as soon as possible because it's affecting my work and productivity.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['Ticket Description'].iloc[456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe5f6804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:20.078737Z",
     "iopub.status.busy": "2024-04-07T05:49:20.078244Z",
     "iopub.status.idle": "2024-04-07T05:49:20.094279Z",
     "shell.execute_reply": "2024-04-07T05:49:20.091843Z"
    },
    "papermill": {
     "duration": 0.04019,
     "end_time": "2024-04-07T05:49:20.097397",
     "exception": false,
     "start_time": "2024-04-07T05:49:20.057207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket Subject Peripheral compatibility \n",
      "Customer Name Jonathan Morris \n",
      "Description I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "[13:01:01] <gordon> that is a bug in the package <0>[10:00:02] <coble I've noticed that the issue occurs consistently when I use a specific feature or application on my {product_purchased}. \n",
      "Solution is Poor charge also quality month.\n",
      "Ticket Subject Installation support \n",
      "Customer Name Luke Vega \n",
      "Description I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "$50,000 - $75,000\n",
      "\n",
      "$80,000 - $100,000\n",
      "\n",
      "$500,000 - $10,000 I've followed the troubleshooting steps mentioned in the user manual, but the issue persists. \n",
      "Solution is Call space water live than strong sort month.\n",
      "Ticket Subject Peripheral compatibility \n",
      "Customer Name James Woods \n",
      "Description I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "0.00015735595957\n",
      "\n",
      "0.00015735595957\n",
      "\n",
      "0.00015735595957\n",
      "\n",
      "0 I've recently updated the firmware of my {product_purchased}, and the issue started happening afterward. Could it be related to the update? \n",
      "Solution is About think term property type.\n"
     ]
    }
   ],
   "source": [
    "similarity_search(\"I'm having an issue with the {product_purchased}. Please assist.\\n\\nQ: Can I buy more than one copy of the item?\\n\\nA: All sales are limited to 1 (1) copy. (Except for I need assistance as soon as possible because it's affecting my work and productivity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f865067",
   "metadata": {
    "papermill": {
     "duration": 0.087151,
     "end_time": "2024-04-07T05:49:20.204515",
     "exception": false,
     "start_time": "2024-04-07T05:49:20.117364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Word2Vec Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b00f9be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:20.247418Z",
     "iopub.status.busy": "2024-04-07T05:49:20.246965Z",
     "iopub.status.idle": "2024-04-07T05:49:56.930874Z",
     "shell.execute_reply": "2024-04-07T05:49:56.929732Z"
    },
    "papermill": {
     "duration": 36.708963,
     "end_time": "2024-04-07T05:49:56.933697",
     "exception": false,
     "start_time": "2024-04-07T05:49:20.224734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "#loading the english language small model of spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d937e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:56.974268Z",
     "iopub.status.busy": "2024-04-07T05:49:56.973534Z",
     "iopub.status.idle": "2024-04-07T05:49:57.030542Z",
     "shell.execute_reply": "2024-04-07T05:49:57.029315Z"
    },
    "papermill": {
     "duration": 0.081321,
     "end_time": "2024-04-07T05:49:57.034264",
     "exception": false,
     "start_time": "2024-04-07T05:49:56.952943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0[\"modified_text\"] = df0['Complete description'].apply(lambda x: \" \".join(word for word in x.split() if word not in stopwords ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f7bde5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:57.076342Z",
     "iopub.status.busy": "2024-04-07T05:49:57.075528Z",
     "iopub.status.idle": "2024-04-07T05:49:57.082482Z",
     "shell.execute_reply": "2024-04-07T05:49:57.081588Z"
    },
    "papermill": {
     "duration": 0.032236,
     "end_time": "2024-04-07T05:49:57.085744",
     "exception": false,
     "start_time": "2024-04-07T05:49:57.053508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket Subject Account access \n",
      "Customer Name Christina Dillon \n",
      "Description I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "If you have a problem you're interested in and I'd love to see this happen, please check out the Feedback. I've already contacted customer support multiple times, but the issue remains unresolved. \n",
      "Solution is Try capital clearly never color toward story.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Ticket Subject Account access Customer Name Christina Dillon Description I'm having issue {product_purchased}. Please assist. If problem you're interested I'd love happen, check Feedback. I've contacted customer support multiple times, issue remains unresolved. Solution Try capital clearly color story.\n"
     ]
    }
   ],
   "source": [
    "print(df0[\"Complete description\"].iloc[1])\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "print(df0[\"modified_text\"].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aef6cf3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:57.129797Z",
     "iopub.status.busy": "2024-04-07T05:49:57.128669Z",
     "iopub.status.idle": "2024-04-07T05:49:57.137226Z",
     "shell.execute_reply": "2024-04-07T05:49:57.136020Z"
    },
    "papermill": {
     "duration": 0.032645,
     "end_time": "2024-04-07T05:49:57.139878",
     "exception": false,
     "start_time": "2024-04-07T05:49:57.107233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Preprocessing the text\n",
    "def clean_text(text):\n",
    "    # lower-case all characters\n",
    "    text=text.lower()\n",
    "    #removing emails\n",
    "    text = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", text)\n",
    "    #removing hashtag and @ words\n",
    "    text= re.sub(r'@\\S+', '',text)\n",
    "    text= re.sub(r'#\\S+', '',text)\n",
    "    # remove urls\n",
    "    text = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , text)\n",
    "    text= re.sub(r'www.\\S+', '',text)\n",
    "    # regex only keeps characters\n",
    "    # text=re.sub(r\"[^a-zA-Z+']\", ' ',text)\n",
    "    #remove 's\n",
    "    text=re.sub(r\"['’]s\\b\",' ',text)\n",
    "    # regex removes repeated spaces, strip removes leading and trailing spaces\n",
    "    text=re.sub(\"\\s[\\s]+\", \" \",text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62d3385d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:57.181895Z",
     "iopub.status.busy": "2024-04-07T05:49:57.181488Z",
     "iopub.status.idle": "2024-04-07T05:49:57.187705Z",
     "shell.execute_reply": "2024-04-07T05:49:57.186453Z"
    },
    "papermill": {
     "duration": 0.030991,
     "end_time": "2024-04-07T05:49:57.190680",
     "exception": false,
     "start_time": "2024-04-07T05:49:57.159689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.replace('[',\"\").replace(\"]\",\"\").replace(\"_\",\" \")\n",
    "    text = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", text)\n",
    "    text=re.sub(\"\\s[\\s]+\", \" \",text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78034ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:57.232549Z",
     "iopub.status.busy": "2024-04-07T05:49:57.231550Z",
     "iopub.status.idle": "2024-04-07T05:49:57.358598Z",
     "shell.execute_reply": "2024-04-07T05:49:57.356889Z"
    },
    "papermill": {
     "duration": 0.150608,
     "end_time": "2024-04-07T05:49:57.361556",
     "exception": false,
     "start_time": "2024-04-07T05:49:57.210948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0[\"modified_text\"] = df0.modified_text.apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5677f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:49:57.403711Z",
     "iopub.status.busy": "2024-04-07T05:49:57.403182Z",
     "iopub.status.idle": "2024-04-07T05:50:01.059307Z",
     "shell.execute_reply": "2024-04-07T05:50:01.058099Z"
    },
    "papermill": {
     "duration": 3.680452,
     "end_time": "2024-04-07T05:50:01.062223",
     "exception": false,
     "start_time": "2024-04-07T05:49:57.381771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "documents = df0['Complete description'].tolist()\n",
    "tokenized_documents = [word_tokenize(doc.lower()) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c82030d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:50:01.105380Z",
     "iopub.status.busy": "2024-04-07T05:50:01.104622Z",
     "iopub.status.idle": "2024-04-07T05:50:02.139829Z",
     "shell.execute_reply": "2024-04-07T05:50:02.138868Z"
    },
    "papermill": {
     "duration": 1.059971,
     "end_time": "2024-04-07T05:50:02.142426",
     "exception": false,
     "start_time": "2024-04-07T05:50:01.082455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_documents, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33151283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:50:02.183919Z",
     "iopub.status.busy": "2024-04-07T05:50:02.183253Z",
     "iopub.status.idle": "2024-04-07T05:50:02.188102Z",
     "shell.execute_reply": "2024-04-07T05:50:02.186966Z"
    },
    "papermill": {
     "duration": 0.028329,
     "end_time": "2024-04-07T05:50:02.190363",
     "exception": false,
     "start_time": "2024-04-07T05:50:02.162034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Search query\n",
    "search_query = \"I'm having an issue with the {product_purchased}. Please assist.\\n\\nQ: Can I buy more than one copy of the item?\\n\\nA: All sales are limited to 1 (1) copy. (Except for I need assistance as soon as possible because it's affecting my work and productivity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c40c760e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:50:02.232607Z",
     "iopub.status.busy": "2024-04-07T05:50:02.231978Z",
     "iopub.status.idle": "2024-04-07T05:50:02.247552Z",
     "shell.execute_reply": "2024-04-07T05:50:02.245884Z"
    },
    "papermill": {
     "duration": 0.042291,
     "end_time": "2024-04-07T05:50:02.252255",
     "exception": false,
     "start_time": "2024-04-07T05:50:02.209964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the search query\n",
    "tokenized_query = word_tokenize(search_query.lower())\n",
    "\n",
    "# Perform similarity search\n",
    "similar_words = word2vec_model.wv.most_similar(positive=tokenized_query, topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86df0e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:50:02.336739Z",
     "iopub.status.busy": "2024-04-07T05:50:02.336069Z",
     "iopub.status.idle": "2024-04-07T05:50:02.344605Z",
     "shell.execute_reply": "2024-04-07T05:50:02.343493Z"
    },
    "papermill": {
     "duration": 0.057621,
     "end_time": "2024-04-07T05:50:02.351384",
     "exception": false,
     "start_time": "2024-04-07T05:50:02.293763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 most similar words to the search query:\n",
      "p.s - 0.9077248573303223\n",
      "remove - 0.8984506726264954\n",
      "1. - 0.8900465965270996\n"
     ]
    }
   ],
   "source": [
    "# Print the most similar words\n",
    "print(\"Top 3 most similar words to the search query:\")\n",
    "for word, similarity in similar_words:\n",
    "    print(word, \"-\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b84311c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:50:02.398483Z",
     "iopub.status.busy": "2024-04-07T05:50:02.398101Z",
     "iopub.status.idle": "2024-04-07T05:50:02.406832Z",
     "shell.execute_reply": "2024-04-07T05:50:02.405674Z"
    },
    "papermill": {
     "duration": 0.032611,
     "end_time": "2024-04-07T05:50:02.409526",
     "exception": false,
     "start_time": "2024-04-07T05:50:02.376915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ticket',\n",
       "  'subject',\n",
       "  'network',\n",
       "  'problem',\n",
       "  'customer',\n",
       "  'name',\n",
       "  'christopher',\n",
       "  'robbins',\n",
       "  'description',\n",
       "  'i',\n",
       "  \"'m\",\n",
       "  'facing',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'with',\n",
       "  'my',\n",
       "  '{',\n",
       "  'product_purchased',\n",
       "  '}',\n",
       "  '.',\n",
       "  'the',\n",
       "  '{',\n",
       "  'product_purchased',\n",
       "  '}',\n",
       "  'is',\n",
       "  'not',\n",
       "  'turning',\n",
       "  'on',\n",
       "  '.',\n",
       "  'it',\n",
       "  'was',\n",
       "  'working',\n",
       "  'fine',\n",
       "  'until',\n",
       "  'yesterday',\n",
       "  ',',\n",
       "  'but',\n",
       "  'now',\n",
       "  'it',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'respond',\n",
       "  '.',\n",
       "  '1.8.3',\n",
       "  'i',\n",
       "  'really',\n",
       "  'i',\n",
       "  \"'m\",\n",
       "  'using',\n",
       "  'the',\n",
       "  'original',\n",
       "  'charger',\n",
       "  'that',\n",
       "  'came',\n",
       "  'with',\n",
       "  'my',\n",
       "  '{',\n",
       "  'product_purchased',\n",
       "  '}',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'not',\n",
       "  'charging',\n",
       "  'properly',\n",
       "  '.',\n",
       "  'solution',\n",
       "  'is',\n",
       "  'case',\n",
       "  'maybe',\n",
       "  'show',\n",
       "  'recently',\n",
       "  'my',\n",
       "  'computer',\n",
       "  'follow',\n",
       "  '.']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02cf2ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T05:50:02.450867Z",
     "iopub.status.busy": "2024-04-07T05:50:02.450188Z",
     "iopub.status.idle": "2024-04-07T05:50:13.308038Z",
     "shell.execute_reply": "2024-04-07T05:50:13.306831Z"
    },
    "papermill": {
     "duration": 10.881789,
     "end_time": "2024-04-07T05:50:13.310799",
     "exception": false,
     "start_time": "2024-04-07T05:50:02.429010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 similar documents to the search query:\n",
      "Ticket Subject Data loss \n",
      "Customer Name Riley Reed \n",
      "Description I'm having an issue with the {product_purchased}. Please assist. Thank you.\"\n",
      "\n",
      "In response to a question about its price, the company said: \"We make what we sell for the satisfaction of consumers, regardless of their I need assistance as soon as possible because it's affecting my work and productivity. \n",
      "Solution is Majority not successful understand.\n",
      "Ticket Subject Product setup \n",
      "Customer Name Terri Johnson \n",
      "Description I'm having an issue with the {product_purchased}. Please assist. [B]Please contact the seller when available and confirm purchase will begin. If we could have added a different price to your cart, we'd be more likely to I need assistance as soon as possible because it's affecting my work and productivity. \n",
      "Solution is Collection commercial rise weight.\n",
      "Ticket Subject Hardware issue \n",
      "Customer Name Justin Knight \n",
      "Description I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "* If you have issues using the product, please contact us.\n",
      "\n",
      "* If you don't know where to get that the product is, please, I need assistance as soon as possible because it's affecting my work and productivity. \n",
      "Solution is Door produce know paper wind figure know.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample text data\n",
    "documents = df0['Complete description'].tolist()\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=[word_tokenize(doc.lower()) for doc in documents], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Search query\n",
    "search_query = \"I'm having an issue with the {product_purchased}. Please assist.\\n\\nQ: Can I buy more than one copy of the item?\\n\\nA: All sales are limited to 1 (1) copy. (Except for I need assistance as soon as possible because it's affecting my work and productivity.\"\n",
    "# Tokenize the search query\n",
    "tokenized_query = word_tokenize(search_query.lower())\n",
    "\n",
    "# Compute average Word2Vec embedding for the search query\n",
    "query_embedding = [word2vec_model.wv[word] for word in tokenized_query if word in word2vec_model.wv]\n",
    "if query_embedding:\n",
    "    query_embedding = sum(query_embedding) / len(query_embedding)\n",
    "else:\n",
    "    # Handle out-of-vocabulary words by skipping the query\n",
    "    print(\"Search query contains out-of-vocabulary words.\")\n",
    "    exit()\n",
    "\n",
    "# Compute cosine similarity between the query embedding and document embeddings\n",
    "similarities = []\n",
    "for doc in documents:\n",
    "    tokenized_doc = word_tokenize(doc.lower())\n",
    "    doc_embedding = [word2vec_model.wv[word] for word in tokenized_doc if word in word2vec_model.wv]\n",
    "    if doc_embedding:\n",
    "        doc_embedding = sum(doc_embedding) / len(doc_embedding)\n",
    "        similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        similarities.append((doc, similarity))\n",
    "\n",
    "# Sort documents by similarity score and return top N similar documents\n",
    "top_similar_documents = sorted(similarities, key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "# Print the top similar documents\n",
    "print(\"Top 3 similar documents to the search query:\")\n",
    "for doc, similarity in top_similar_documents:\n",
    "    print(doc)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3349722,
     "sourceId": 5828126,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 91.291731,
   "end_time": "2024-04-07T05:50:15.938960",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-07T05:48:44.647229",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
